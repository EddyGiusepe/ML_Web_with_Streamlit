{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\">NLP: Reconhecimento de produtos</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Scientist.: Dr.Eddy Giusepe Chirinos Isidro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste script vamos a estudar e aprender uma `tarefa de classificação` usando `Python` e as técnicas de Processamento de Linguagem Natural - clássico (NLP - Clássico).\n",
    "\n",
    "Como sabemos, a `NLP` é a área de estudo que busca fazer com que a máquina possa compreender e simular a linguagem humana. Em outras palavras, é fazer o computador receber uma frase e ter uma \"opinião\" sobre ela. Alguns exemplos de aplicação:\n",
    "\n",
    "* Classificação de texto\n",
    "\n",
    "* Análise de sentimentos\n",
    "\n",
    "* Chatbots e assistentes virtuais, etc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Links de estudo:\n",
    "\n",
    "* [Streamlit: Predição de flores Iris](https://acervolima.com/implante-um-modelo-de-aprendizado-de-maquina-usando-a-biblioteca-streamlit/)\n",
    "\n",
    "* [Streamlit: Análise de estoque de produtos ](https://www.alura.com.br/artigos/streamlit-compartilhando-sua-aplicacao-de-dados-sem-dor-de-cabeca)\n",
    "\n",
    "* [Análise de produtos de supermercado](https://dadosaocubo.com/nlp-com-scikit-learn/)\n",
    "\n",
    "* [Streamlit: produtos de supermercado](https://dadosaocubo.com/modelos-em-producao-com-streamlit/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importando as bibliotecas necessárias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A seguir temos as bibliotecas que nos ajudará nesta tarefa de classificação. Vamos usar a plataforma [NLTK - Natural Language ToolKit](https://www.nltk.org/) para construir programas Python para trabalhar com dados de linguagem humana, uso de expressões regulares (`REGEX`), etc.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/eddygiusepe/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/eddygiusepe/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from wordcloud import WordCloud\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregando nosso Dataset e preparando ele "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sabemos que a preparação de Dados é muito importante para qualquer modelo de Machine Learning. Para as tarefas de NLP não é diferente, um bom tratamento do texto pode levar nosso modelo a resultados incríveis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>descricao</th>\n",
       "      <th>departamento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PASTA INT VITAPOWER 1,005KG AMEND/SHOT</td>\n",
       "      <td>MERCEARIA DOCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ESPONJA BETTANIN BRILHUS C/1</td>\n",
       "      <td>CUIDADOS COM A COZINHA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AGUA MIN SCHIN S/GAS 500ML</td>\n",
       "      <td>BEBIDAS NÃO ALCOÓLICAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FITA DUPLA FACE C/SUPORTE SCOTCH</td>\n",
       "      <td>PAPELARIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MASSA PIZZA ROMANHA OREGANO PCT 160G</td>\n",
       "      <td>MASSAS FRESCAS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                descricao            departamento\n",
       "0  PASTA INT VITAPOWER 1,005KG AMEND/SHOT          MERCEARIA DOCE\n",
       "1            ESPONJA BETTANIN BRILHUS C/1  CUIDADOS COM A COZINHA\n",
       "2              AGUA MIN SCHIN S/GAS 500ML  BEBIDAS NÃO ALCOÓLICAS\n",
       "3        FITA DUPLA FACE C/SUPORTE SCOTCH               PAPELARIA\n",
       "4    MASSA PIZZA ROMANHA OREGANO PCT 160G          MASSAS FRESCAS"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carregando nosso Dataset\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/dadosaocubo/nlp/master/base_mercadologica.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22009, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['MERCEARIA DOCE', 'CUIDADOS COM A COZINHA',\n",
       "       'BEBIDAS NÃO ALCOÓLICAS', 'PAPELARIA', 'MASSAS FRESCAS',\n",
       "       'BEBIDAS ALCOÓLICAS', 'CUIDADOS COM O CORPO', 'CONGELADOS DOCES',\n",
       "       'MERCEARIA SALGADA', 'CUIDADOS COM O CABELO',\n",
       "       'UTILIDADES DE COZINHA', 'CUIDADOS COM A ROUPA', 'AÇOUGUE',\n",
       "       'CALÇADO', 'ELETRO', 'PET SHOP', 'GORDUROSOS', 'HORTIFRUTI',\n",
       "       'DESCARTÁVEIS', 'HIGIENE PESSOAL', 'EMPÓRIO',\n",
       "       'CUIDADOS COM A CASA', 'BRINQUEDO', 'CAMA, MESA E BANHO',\n",
       "       'SALGADO', 'LAVANDERIA', 'JARDINAGEM', 'HIGIENE PESSOAL INFANTIL',\n",
       "       'FRIOS', 'PADARIA', 'DECORAÇÃO', 'MANUTENÇÃO', 'LAZER/CAMPING',\n",
       "       'RESFRIADOS', 'CUIDADOS COM MÃOS E PÉS', 'CUIDADOS COM O BANHEIRO',\n",
       "       'CUIDADOS COM O ROSTO', 'EMBUTIDOS', 'LEITE',\n",
       "       'CONGELADOS SALGADOS', 'HIGIENE ORAL', 'TEXTIL', 'PRATOS PRONTOS',\n",
       "       'CUIDADOS COM A BARBA', 'IOGURTES', 'TABACO', 'INFANTIL',\n",
       "       'PEIXARIA', 'AUTOMOTIVO', 'MALAS/NECESSAIRES',\n",
       "       'UTILIDADES DE BANHEIRO', 'SALGADOS', 'CUIDADOS COM OS OLHOS'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tipos de departamentos:\n",
    "df['departamento'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quantidade de departamentos\n",
    "len(df['departamento'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criamos uma nova coluna\n",
    "df['nova_descricao'] = df['descricao'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>descricao</th>\n",
       "      <th>departamento</th>\n",
       "      <th>nova_descricao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PASTA INT VITAPOWER 1,005KG AMEND/SHOT</td>\n",
       "      <td>MERCEARIA DOCE</td>\n",
       "      <td>PASTA INT VITAPOWER 1,005KG AMEND/SHOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ESPONJA BETTANIN BRILHUS C/1</td>\n",
       "      <td>CUIDADOS COM A COZINHA</td>\n",
       "      <td>ESPONJA BETTANIN BRILHUS C/1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AGUA MIN SCHIN S/GAS 500ML</td>\n",
       "      <td>BEBIDAS NÃO ALCOÓLICAS</td>\n",
       "      <td>AGUA MIN SCHIN S/GAS 500ML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FITA DUPLA FACE C/SUPORTE SCOTCH</td>\n",
       "      <td>PAPELARIA</td>\n",
       "      <td>FITA DUPLA FACE C/SUPORTE SCOTCH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MASSA PIZZA ROMANHA OREGANO PCT 160G</td>\n",
       "      <td>MASSAS FRESCAS</td>\n",
       "      <td>MASSA PIZZA ROMANHA OREGANO PCT 160G</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                descricao            departamento  \\\n",
       "0  PASTA INT VITAPOWER 1,005KG AMEND/SHOT          MERCEARIA DOCE   \n",
       "1            ESPONJA BETTANIN BRILHUS C/1  CUIDADOS COM A COZINHA   \n",
       "2              AGUA MIN SCHIN S/GAS 500ML  BEBIDAS NÃO ALCOÓLICAS   \n",
       "3        FITA DUPLA FACE C/SUPORTE SCOTCH               PAPELARIA   \n",
       "4    MASSA PIZZA ROMANHA OREGANO PCT 160G          MASSAS FRESCAS   \n",
       "\n",
       "                           nova_descricao  \n",
       "0  PASTA INT VITAPOWER 1,005KG AMEND/SHOT  \n",
       "1            ESPONJA BETTANIN BRILHUS C/1  \n",
       "2              AGUA MIN SCHIN S/GAS 500ML  \n",
       "3        FITA DUPLA FACE C/SUPORTE SCOTCH  \n",
       "4    MASSA PIZZA ROMANHA OREGANO PCT 160G  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificamos essa nova coluna\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nessa nova coluna vamos tratar a pontuação, acentuação, caracteres especiais, palavras vazias (`stop words`) e números, que são caracteres que interferem na análise do texto. Em nosso caso a pontuação não é tão relevante para a identificação de um produto, mas MUITO CUIDADO em outro contexto. <font color=\"orange\">Por exemplo em análsie de sentimentos</font>: quando um texto contém  `?` e quando não contém `?`. \n",
    "\n",
    "Começamos com a puntuação e acentuação (aplicamos `regex`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['nova_descricao'] = df['nova_descricao'].str.replace('[,.:;!?]+', ' ', regex=True).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>descricao</th>\n",
       "      <th>departamento</th>\n",
       "      <th>nova_descricao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PASTA INT VITAPOWER 1,005KG AMEND/SHOT</td>\n",
       "      <td>MERCEARIA DOCE</td>\n",
       "      <td>PASTA INT VITAPOWER 1 005KG AMEND/SHOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ESPONJA BETTANIN BRILHUS C/1</td>\n",
       "      <td>CUIDADOS COM A COZINHA</td>\n",
       "      <td>ESPONJA BETTANIN BRILHUS C/1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AGUA MIN SCHIN S/GAS 500ML</td>\n",
       "      <td>BEBIDAS NÃO ALCOÓLICAS</td>\n",
       "      <td>AGUA MIN SCHIN S/GAS 500ML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FITA DUPLA FACE C/SUPORTE SCOTCH</td>\n",
       "      <td>PAPELARIA</td>\n",
       "      <td>FITA DUPLA FACE C/SUPORTE SCOTCH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MASSA PIZZA ROMANHA OREGANO PCT 160G</td>\n",
       "      <td>MASSAS FRESCAS</td>\n",
       "      <td>MASSA PIZZA ROMANHA OREGANO PCT 160G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BISC LANCH BAUDUCCO RECHEADINHO CHOCOLATE 104G</td>\n",
       "      <td>MERCEARIA DOCE</td>\n",
       "      <td>BISC LANCH BAUDUCCO RECHEADINHO CHOCOLATE 104G</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        descricao            departamento  \\\n",
       "0          PASTA INT VITAPOWER 1,005KG AMEND/SHOT          MERCEARIA DOCE   \n",
       "1                    ESPONJA BETTANIN BRILHUS C/1  CUIDADOS COM A COZINHA   \n",
       "2                      AGUA MIN SCHIN S/GAS 500ML  BEBIDAS NÃO ALCOÓLICAS   \n",
       "3                FITA DUPLA FACE C/SUPORTE SCOTCH               PAPELARIA   \n",
       "4            MASSA PIZZA ROMANHA OREGANO PCT 160G          MASSAS FRESCAS   \n",
       "5  BISC LANCH BAUDUCCO RECHEADINHO CHOCOLATE 104G          MERCEARIA DOCE   \n",
       "\n",
       "                                   nova_descricao  \n",
       "0          PASTA INT VITAPOWER 1 005KG AMEND/SHOT  \n",
       "1                    ESPONJA BETTANIN BRILHUS C/1  \n",
       "2                      AGUA MIN SCHIN S/GAS 500ML  \n",
       "3                FITA DUPLA FACE C/SUPORTE SCOTCH  \n",
       "4            MASSA PIZZA ROMANHA OREGANO PCT 160G  \n",
       "5  BISC LANCH BAUDUCCO RECHEADINHO CHOCOLATE 104G  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vejamos os cambios\n",
    "df.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos remover os `caracteres especiais` (#, $, &, /, *, %, etc) na descrição dos itens. Façamos isso com regex, assim:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['nova_descricao'] = df['nova_descricao'].str.replace ('[/<>()|\\+\\-\\$%&#@\\'\\\"]+', ' ', regex=True).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>descricao</th>\n",
       "      <th>departamento</th>\n",
       "      <th>nova_descricao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PASTA INT VITAPOWER 1,005KG AMEND/SHOT</td>\n",
       "      <td>MERCEARIA DOCE</td>\n",
       "      <td>PASTA INT VITAPOWER 1 005KG AMEND SHOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ESPONJA BETTANIN BRILHUS C/1</td>\n",
       "      <td>CUIDADOS COM A COZINHA</td>\n",
       "      <td>ESPONJA BETTANIN BRILHUS C 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AGUA MIN SCHIN S/GAS 500ML</td>\n",
       "      <td>BEBIDAS NÃO ALCOÓLICAS</td>\n",
       "      <td>AGUA MIN SCHIN S GAS 500ML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FITA DUPLA FACE C/SUPORTE SCOTCH</td>\n",
       "      <td>PAPELARIA</td>\n",
       "      <td>FITA DUPLA FACE C SUPORTE SCOTCH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MASSA PIZZA ROMANHA OREGANO PCT 160G</td>\n",
       "      <td>MASSAS FRESCAS</td>\n",
       "      <td>MASSA PIZZA ROMANHA OREGANO PCT 160G</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                descricao            departamento  \\\n",
       "0  PASTA INT VITAPOWER 1,005KG AMEND/SHOT          MERCEARIA DOCE   \n",
       "1            ESPONJA BETTANIN BRILHUS C/1  CUIDADOS COM A COZINHA   \n",
       "2              AGUA MIN SCHIN S/GAS 500ML  BEBIDAS NÃO ALCOÓLICAS   \n",
       "3        FITA DUPLA FACE C/SUPORTE SCOTCH               PAPELARIA   \n",
       "4    MASSA PIZZA ROMANHA OREGANO PCT 160G          MASSAS FRESCAS   \n",
       "\n",
       "                           nova_descricao  \n",
       "0  PASTA INT VITAPOWER 1 005KG AMEND SHOT  \n",
       "1            ESPONJA BETTANIN BRILHUS C 1  \n",
       "2              AGUA MIN SCHIN S GAS 500ML  \n",
       "3        FITA DUPLA FACE C SUPORTE SCOTCH  \n",
       "4    MASSA PIZZA ROMANHA OREGANO PCT 160G  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vejamos, novamente, esses cambios\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em problemas de classificação de texto, os números podem confundir os classifadores, diminuindo a assertividade dos mesmos. A seguir vamos a remover os números, assim:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['nova_descricao'] = df['nova_descricao'].str.replace('[0-9]+', '', regex=True).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>descricao</th>\n",
       "      <th>departamento</th>\n",
       "      <th>nova_descricao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PASTA INT VITAPOWER 1,005KG AMEND/SHOT</td>\n",
       "      <td>MERCEARIA DOCE</td>\n",
       "      <td>PASTA INT VITAPOWER  KG AMEND SHOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ESPONJA BETTANIN BRILHUS C/1</td>\n",
       "      <td>CUIDADOS COM A COZINHA</td>\n",
       "      <td>ESPONJA BETTANIN BRILHUS C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AGUA MIN SCHIN S/GAS 500ML</td>\n",
       "      <td>BEBIDAS NÃO ALCOÓLICAS</td>\n",
       "      <td>AGUA MIN SCHIN S GAS ML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FITA DUPLA FACE C/SUPORTE SCOTCH</td>\n",
       "      <td>PAPELARIA</td>\n",
       "      <td>FITA DUPLA FACE C SUPORTE SCOTCH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MASSA PIZZA ROMANHA OREGANO PCT 160G</td>\n",
       "      <td>MASSAS FRESCAS</td>\n",
       "      <td>MASSA PIZZA ROMANHA OREGANO PCT G</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                descricao            departamento  \\\n",
       "0  PASTA INT VITAPOWER 1,005KG AMEND/SHOT          MERCEARIA DOCE   \n",
       "1            ESPONJA BETTANIN BRILHUS C/1  CUIDADOS COM A COZINHA   \n",
       "2              AGUA MIN SCHIN S/GAS 500ML  BEBIDAS NÃO ALCOÓLICAS   \n",
       "3        FITA DUPLA FACE C/SUPORTE SCOTCH               PAPELARIA   \n",
       "4    MASSA PIZZA ROMANHA OREGANO PCT 160G          MASSAS FRESCAS   \n",
       "\n",
       "                       nova_descricao  \n",
       "0  PASTA INT VITAPOWER  KG AMEND SHOT  \n",
       "1         ESPONJA BETTANIN BRILHUS C   \n",
       "2             AGUA MIN SCHIN S GAS ML  \n",
       "3    FITA DUPLA FACE C SUPORTE SCOTCH  \n",
       "4   MASSA PIZZA ROMANHA OREGANO PCT G  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As `palavras vazias` ou `stop words`, como são mais conhecidas, são palavras que não agregam sentidos as frases, <font color=\"yellow\">por exemplo:</font> `conjunções`, `artigos` e `pronomes`. Não existe uma lista definitiva com essas palavras, como sempre essa análise vai depender do problema.\n",
    "\n",
    "\n",
    "Vou mostrar a lista de `stop words` em `português` da biblioteca `NLTK`, que pode ser uma base inicial de partida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['a', 'à', 'ao', 'aos', 'aquela', 'aquelas', 'aquele', 'aqueles', 'aquilo', 'as', 'às', 'até', 'com', 'como', 'da', 'das', 'de', 'dela', 'delas', 'dele', 'deles', 'depois', 'do', 'dos', 'e', 'é', 'ela', 'elas', 'ele', 'eles', 'em', 'entre', 'era', 'eram', 'éramos', 'essa', 'essas', 'esse', 'esses', 'esta', 'está', 'estamos', 'estão', 'estar', 'estas', 'estava', 'estavam', 'estávamos', 'este', 'esteja', 'estejam', 'estejamos', 'estes', 'esteve', 'estive', 'estivemos', 'estiver', 'estivera', 'estiveram', 'estivéramos', 'estiverem', 'estivermos', 'estivesse', 'estivessem', 'estivéssemos', 'estou', 'eu', 'foi', 'fomos', 'for', 'fora', 'foram', 'fôramos', 'forem', 'formos', 'fosse', 'fossem', 'fôssemos', 'fui', 'há', 'haja', 'hajam', 'hajamos', 'hão', 'havemos', 'haver', 'hei', 'houve', 'houvemos', 'houver', 'houvera', 'houverá', 'houveram', 'houvéramos', 'houverão', 'houverei', 'houverem', 'houveremos', 'houveria', 'houveriam']\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lista com as 50 primeiras stop words da biblioteca NLTK\n",
    "str(stopwords.words('portuguese')[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Devido a nosso problema ser particular, as palavras da biblioteca NLTK não abrange nossos itens \n",
    "# Criamos um objeto do tipo lista com todas as nossas stop words\n",
    "stop_words = ['em','sao','ao','de','da','do','para','c','kg','un',\n",
    "              'ml','pct','und','das','no','ou','pc','gr','pt','cm',\n",
    "              'vd','com','sem','gfa','jg','la','1','2','3','4','5',\n",
    "              '6','7','8','9','0','a','b','c','d','e','lt','f','g',\n",
    "              'h','i','j','k','l','m','n','o','p','q','r','s','t',\n",
    "              'u','v','x','w','y','z']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos a entender a `tokenização` e a transformação desses `tokens` em vetores, para que possa ser entendido por nosso algoritmo. Basicamente, a tokenização é a forma de separação do texto em tokens, ou seja, decompor o texto por cada termo. \n",
    "\n",
    "A seguir mostramos um exemplo simples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sou',\n",
       " 'estudante',\n",
       " 'da',\n",
       " 'UFES',\n",
       " 'e',\n",
       " 'faço',\n",
       " 'parte',\n",
       " 'do',\n",
       " 'laboratório',\n",
       " 'de',\n",
       " 'pesquisa',\n",
       " 'LabVISIO',\n",
       " ',',\n",
       " 'na',\n",
       " 'Engenharia',\n",
       " 'Elétrica',\n",
       " '.']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frase = 'Sou estudante da UFES e faço parte do laboratório de pesquisa LabVISIO, na Engenharia Elétrica.'\n",
    "nltk.word_tokenize(frase)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação da função CountVectorizer do scikit-learn.\n",
    "cvt = CountVectorizer(strip_accents='ascii', \n",
    "                      lowercase=True, \n",
    "                      stop_words=stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 1, 1, 1, 1],\n",
       "       [0, 1, 1, 1, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Seleção de dois itens da base de dados\n",
    "exemplo_descricao = df['nova_descricao'][:2]\n",
    "exemplo_descricao.values\n",
    " \n",
    "np.array(['PASTA INT VITAPOWER  KG AMEND SHOT',\n",
    "       'ESPONJA BETTANIN BRILHUS C '], dtype=object)\n",
    " \n",
    "# Transformação dos dois itens em vetores binários\n",
    "exemplo_descricao_cvt = cvt.fit_transform(exemplo_descricao)\n",
    "exemplo_descricao_cvt.toarray()\n",
    " \n",
    "np.array([[1, 0, 0, 0, 1, 1, 1, 1],\n",
    "       [0, 1, 1, 1, 0, 0, 0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cvt = cvt.fit_transform(df['nova_descricao'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse._csr.csr_matrix"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_cvt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação da função TfidfTransformer\n",
    "tfi = TfidfTransformer(use_idf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4472136 , 0.        , 0.        , 0.        , 0.4472136 ,\n",
       "        0.4472136 , 0.4472136 , 0.4472136 ],\n",
       "       [0.        , 0.57735027, 0.57735027, 0.57735027, 0.        ,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transformação dos exemplos com a normalização tf-idf\n",
    "exemplo_descricao_tfi = tfi.fit_transform(exemplo_descricao_cvt)\n",
    "exemplo_descricao_tfi.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfi = tfi.fit_transform(X_cvt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse._csr.csr_matrix"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_tfi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A entrada será a transformação de vetores com a normalização tf-idf\n",
    "entrada = X_tfi\n",
    "# A saida será os departamentos\n",
    "saida = df['departamento']\n",
    "# Separando 20% dos dados para teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(entrada, \n",
    "                                                    saida, \n",
    "                                                    test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criando modelo\n",
    "clf = LinearSVC()\n",
    "# Treinamento do modelo\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.95\n"
     ]
    }
   ],
   "source": [
    "# Realizando a predição\n",
    "resultado = clf.predict(X_test)\n",
    "# Avaliando o modelo\n",
    "print('Acurácia: {:.2f}'.format(metrics.accuracy_score(y_test, resultado)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">Siga o seguinte exemplo, para salvar os modelos que treinei neste script</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/clfEddy.joblib']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Salvando nosso Modelo\n",
    "\n",
    "#from sklearn.externals import joblib  <-- Isto dá ERRO não usar\n",
    "import joblib \n",
    "from joblib import dump, load\n",
    "\n",
    "dump(clf, 'models/clfEddy.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def novo_item(descricao):\n",
    "  novo_cvt = cvt.transform(pd.Series(descricao))\n",
    "  novo_tfi = tfi.transform(novo_cvt)\n",
    "  departamento = clf.predict(novo_tfi)[0]\n",
    "  return departamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Produto: FEIJÃO Departamento: MERCEARIA SALGADA\n",
      "Produto: AÇÚCAR Departamento: MERCEARIA DOCE\n",
      "Produto: ALFACE Departamento: HORTIFRUTI\n"
     ]
    }
   ],
   "source": [
    "# Lista de exemplos de novos produtos\n",
    "itens = ['FEIJÃO','AÇÚCAR','ALFACE']\n",
    "# Loop for para fazer a predição do departamento de novos produtos\n",
    "for item in itens:\n",
    "  print('Produto:', item, 'Departamento:', novo_item(item))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
